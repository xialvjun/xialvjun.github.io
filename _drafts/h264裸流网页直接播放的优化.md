
# h264 裸流网页直接播放的优化

部标平台视频回放里，设备上传的视频是 h264 裸流文件，而非封装好的 mp4 文件，目前需要服务器对视频用 ffmpeg 封装一下。

后端考虑这种操作可能会在未来产生性能风险，所以前端这两天探究了下浏览器直接播放 h264 裸流文件的方案。

目前已经可以在前端直接播放 h264 裸流文件，但是还做不到拖动进度条。

然后我研究了下 h264 裸流文件格式，用 ffprobe 看了下 h264 和 mp4 文件的元信息

```
# 264
Input #0, h264, from 'test.264':
  Duration: N/A, bitrate: N/A
  Stream #0:0: Video: h264 (Main), yuv420p(progressive), 288x704, 25 fps, 25 tbr, 1200k tbn

# mp4
Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'copy.mp4':
  Metadata:
    major_brand     : isom
    minor_version   : 512
    compatible_brands: isomiso2avc1mp41
    encoder         : Lavf59.16.100
  Duration: 00:21:32.00, start: 0.000000, bitrate: 622 kb/s
  Stream #0:0[0x1](und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(progressive), 288x704, 621 kb/s, 25 fps, 25 tbr, 1200k tbn (default)
    Metadata:
      handler_name    : VideoHandler
      vendor_id       : [0][0][0][0]
```

https://www.cnblogs.com/valin/articles/3228864.html

另外尝试了下市面上常见的视频播放器，配合支持 http Range header 的 web 服务器，看到 mpc-hc 播放 h264 没有进度条，ffplay/mpv/vlc 能拖动进度（ffplay 没有 gui 界面不说，mpv 的进度条在每次拖动的时候，播放时长就置零了，vlc 比 mpv 还差，有进度条，但一直没有播放时间，拖动还花屏），配合 h264 裸流文件格式的理解，可以想到：

> http Range header 是 web 服务器在收到浏览器请求文件的请求时，根据文件类型决定在响应头上加 Content-Range: bytes 0-NNNN/MMMMM 告诉客户端文件总共有多大，然后之后客户端发请求时可以发 Range: bytes=AAAA- 告诉服务器从文件的第 AAAA 字节开始返回内容，从而实现文件内容的定点获取。

从上面的元信息对比中可以看到，mp4 相比 h264 仅仅只多了个 时长Duration 和 比特率bitrate(要说明的是现在大部分媒体文件都非固定比特率，而是动态比特率，于是这里的比特率都是指平均比特率，平均比特率其实就是视频大小除以时长)，也就是说 mp4 比 h264 就多一个视频时长，另外还从[这里](https://bbs.csdn.net/topics/390839947#:~:text=%E6%97%B6%E9%97%B4%E6%88%B3%E4%BF%A1%E6%81%AF,2)了解到 mp4 作为封装格式，还比 h264裸流 多了个关键帧的时间戳。现在我们可以理解到各种操作的原理了：

1. 浏览器播放由支持 Range header 的服务器提供的 mp4 文件，可以定点拖动的原因是：拖动到一个位置后得到一个百分比，根据这个百分比对应 Range header 去请求文件，拿到中间的片段的内容，解析内容，找到第一个（也就是最近的）有时间戳的关键帧，进度条定位到这个时间戳相比一开始就获取到的视频总时长得到的百分比处，同时视频的播放时间也设置到这个时间戳处，开始播放。

2. mpv 播放由支持 Range header 的服务器提供的 h264 裸流文件，可以定点拖动，但一拖动，播放时长就置零的原因：跟 1 一样，根据百分比请求片段内容，但是 h264 裸流文件没有帧的时间戳，尽管 mpv 知道前面的部分有多大，但它不知道前面的部分有多少帧（因为动态比特率），有多少时长，mpv 就只能直接播放第一个解析到的关键帧，进度条也不按真实的去调整，播放时长也只能置零。可是 mpv 在播放的时候，进度条也能慢慢前进，它是基于什么前进的呢？猜测可能此时进度条是完全的 buffer 进度条，而非视频时长进度条。

综上，只有 h264裸流 从理论上就做不到完美的播放。最理想的情况也只能做到类似 mpv 那样，提供一个 buffer 进度条，而非视频时间进度条，而且这样会脱离整个社区，对以后的视频相关的开发，就难以再利用社区资源了，例如用 video.js 等。

其实我个人不太理解后端转换的瓶颈在哪里，目前我知道 ffmpeg 封装 h264 为 mp4 其实基本消耗不了多少 CPU/内存，主要是读写文件有一定的 IO 开销。一个 90MB 的视频，封装好，个人电脑用差不多 1s，服务器理应会更低。可以设备上传之后就立即转换，可以用户请求时在去转换这样延迟操作（只要IO够快，整体转换的时间控制在一定以内，让用户等个几秒感觉问题并不大），或者两个结合起来。另外可能考虑启动 ffmpeg 是启动进程，进程过多会影响系统，那也可以用 worker 模式解决。

# H264Video.vue

```vue
<script lang="ts">
import { defineComponent, getCurrentInstance, PropType, shallowRef, watch, onMounted, onBeforeUnmount } from '@vue/composition-api';

// import VideoConverter from './h264-converter';
// setLogger(console.log);

import JMuxer from 'jmuxer';

// import muxjs from 'mux.js';

export default defineComponent({
  props: {
    src: String,
  },
  setup(props, ctx) {
    const insp = getCurrentInstance()!.proxy;

    // onMounted(() => {
    //   const transmuxer = new muxjs.mp4.Transmuxer({});
    //   // insp.vc = vc;
    //   // ctx.expose({ vc });
    //   watch(
    //     () => props.src,
    //     async (cv, _, inv) => {
    //       // vc.reset();
    //       if (!cv) return;
    //       const res = await fetch(cv);
    //       if (!res.body) return;
    //       const reader = res.body.getReader();
    //       reader.read().then(function processResult(result): any {
    //         function decode(value: any) {
    //           vc.appendRawData(value);
    //         }
    //         if (result.done) {
    //           decode([]);
    //           console.log('Video Stream is done.');
    //           return Promise.resolve();
    //         }
    //         decode(result.value);
    //         return reader.read().then(processResult);
    //       });
    //       // vc.play();
    //       inv(() => {
    //         reader.cancel();
    //         console.log('Video Stream Request Canceled');
    //       });
    //     },
    //     { immediate: true }
    //   );
    // });

    onMounted(() => {
      watch(
        () => props.src,
        async (cv, _, inv) => {
          if (!cv) return;
          const res = await fetch(cv);
          if (!res.body) return;
          const reader = res.body.getReader();
          const jmuxer = new JMuxer({
            node: insp.$el,
            mode: 'video',
            readFpsFromTrack: true,
            onReady: () => {
              reader.read().then(function processResult(result) {
                // if (result.done) {
                //   jmuxer.feed({ video: [] });
                //   return;
                // }
                // jmuxer.feed({ video: result.value });
                // reader.read().then(processResult);
                jmuxer.feed({ video: result.value || [] });
                !result.done && reader.read().then(processResult);
              });
            },
          });
          inv(() => {
            jmuxer.destroy();
            reader.cancel();
          });
        },
        { immediate: true }
      );
    });

    // 下面这个可能会清除不彻底，例如 变更 发生在 fetch 处。上面那个可能造成没清除，例如在执行到 inv 之前就再次发生了变更，这里不清楚 vue 会不会记得上一次的 inv 要立即执行。或者再下一次变更要执行两个 inv 。。。 可以用 abortSignal
    // onMounted(() => {
    //   watch(
    //     () => props.src,
    //     async (cv, _, inv) => {
    //       let jmuxer: JMuxer = null!;
    //       let reader: Awaited<ReturnType<NonNullable<Response['body']>['getReader']>> = null!;
    //       inv(() => {
    //         reader?.cancel();
    //         jmuxer?.destroy();
    //       });
    //       if (!cv) return;
    //       jmuxer = new JMuxer({
    //         // debug: true,
    //         node: insp.$el,
    //         mode: 'video',
    //         readFpsFromTrack: true,
    //         onReady: async () => {
    //           const res = await fetch(cv);
    //           if (!res.body) return;
    //           reader = res.body.getReader();
    //           while (true) {
    //             const result = await reader.read();
    //             jmuxer.feed({ video: result.value || [] });
    //             if (result.done) break;
    //           }
    //         },
    //         // onError: (...args) => {
    //         //   console.error(args);
    //         // },
    //       });
    //     },
    //     { immediate: true }
    //   );
    // });

    // onMounted(() => {
    //   const vc = new VideoConverter(insp.$el as any, 24, 1);
    //   // insp.vc = vc;
    //   // ctx.expose({ vc });
    //   watch(
    //     () => props.src,
    //     async (cv, _, inv) => {
    //       vc.reset();
    //       if (!cv) return;
    //       const res = await fetch(cv);
    //       if (!res.body) return;
    //       const reader = res.body.getReader();
    //       reader.read().then(function processResult(result): any {
    //         function decode(value: any) {
    //           vc.appendRawData(value);
    //         }
    //         if (result.done) {
    //           decode([]);
    //           console.log('Video Stream is done.');
    //           return Promise.resolve();
    //         }
    //         decode(result.value);
    //         return reader.read().then(processResult);
    //       });
    //       // vc.play();
    //       inv(() => {
    //         reader.cancel();
    //         console.log('Video Stream Request Canceled');
    //       });
    //     },
    //     { immediate: true }
    //   );
    // });

    return {};
  },
});
</script>

<template>
  <video></video>
</template>
```
